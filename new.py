# KBS êµ­ì œ ë‰´ìŠ¤ í¬ë¡¤ë§ (ì—¬ëŸ¬ í˜ì´ì§€) + OpenAI ìš”ì•½
# Seleniumìœ¼ë¡œ ë™ì  í˜ì´ì§€ í¬ë¡¤ë§

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
from openai import OpenAI
import time
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì • (.env íŒŒì¼ì—ì„œ ìë™ ë¡œë“œ)
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

client = OpenAI(api_key=api_key)

# ë‰´ìŠ¤ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜
def summarize_news(content):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë‚´ìš©ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{content}"}
            ],
            max_tokens=200,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"  âœ— ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

# Chrome ì˜µì…˜ ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¸°ê¸° (ì›í•˜ë©´ ì œê±°)
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# WebDriver ì´ˆê¸°í™”
driver = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(driver, 10)

# KBS êµ­ì œ ë‰´ìŠ¤ í˜ì´ì§€
base_url = "https://news.kbs.co.kr/news/pc/category/category.do?ctcd=0006&ref=pSiteMap"

data = []
MAX_PAGES = 3  # í¬ë¡¤ë§í•  í˜ì´ì§€ ìˆ˜ (ì›í•˜ëŠ” ë§Œí¼ ì¡°ì •)

try:
    print(f"KBS êµ­ì œ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘ (ìµœëŒ€ {MAX_PAGES}í˜ì´ì§€)\n")
    driver.get(base_url)
    time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

    # í˜„ì¬ ë‚ ì§œ í™•ì¸
    current_date = driver.find_element(By.CSS_SELECTOR, ".datepicker-label .date").text
    print(f"ğŸ“… í¬ë¡¤ë§ ë‚ ì§œ: {current_date}\n")

    for page_num in range(1, MAX_PAGES + 1):
        print(f"{'='*60}")
        print(f"ğŸ“„ í˜ì´ì§€ {page_num} í¬ë¡¤ë§ ì¤‘...")
        print(f"{'='*60}\n")

        # í˜„ì¬ í˜ì´ì§€ì˜ HTML ê°€ì ¸ì˜¤ê¸°
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, "html.parser")

        # ë‰´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        news_items = soup.select(".box-contents.has-wrap .box-content")
        print(f"ì´ í˜ì´ì§€ì˜ ë‰´ìŠ¤ ê°œìˆ˜: {len(news_items)}\n")

        for idx, item in enumerate(news_items, 1):
            try:
                # ë‰´ìŠ¤ ë§í¬
                link = item.get("href")
                if not link:
                    continue

                news_url = "https://news.kbs.co.kr" + link

                # ì œëª©
                title_elem = item.select_one(".title")
                title = title_elem.text.strip() if title_elem else "ì œëª© ì—†ìŒ"

                # ë‚ ì§œ
                date_elem = item.select_one(".field-writer .date")
                date = date_elem.text.strip() if date_elem else "ë‚ ì§œ ì—†ìŒ"

                print(f"  [{page_num}-{idx}] {title[:40]}...")
                print(f"       ë‚ ì§œ: {date}")

                # ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
                driver.execute_script(f"window.open('{news_url}', '_blank');")
                driver.switch_to.window(driver.window_handles[1])
                time.sleep(2)

                # ë³¸ë¬¸ ë‚´ìš© í¬ë¡¤ë§
                detail_soup = BeautifulSoup(driver.page_source, "html.parser")
                content_elem = detail_soup.select_one("#cont_newstext")
                content = content_elem.text.strip() if content_elem else "ë‚´ìš© ì—†ìŒ"

                # OpenAI ìš”ì•½
                print(f"       ìš”ì•½ ìƒì„± ì¤‘...")
                summary = summarize_news(content)

                # ë°ì´í„° ì €ì¥
                data.append([date, title, content, summary])
                print(f"       âœ“ ì™„ë£Œ\n")

                # íƒ­ ë‹«ê³  ì›ë˜ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°
                driver.close()
                driver.switch_to.window(driver.window_handles[0])

                time.sleep(1)  # API ì œí•œ ë°©ì§€

            except Exception as e:
                print(f"       âœ— ì˜¤ë¥˜: {e}\n")
                # íƒ­ì´ ì—´ë ¤ìˆìœ¼ë©´ ë‹«ê¸°
                if len(driver.window_handles) > 1:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                continue

        # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
        if page_num < MAX_PAGES:
            try:
                print(f"\nâ­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...\n")
                next_button = driver.find_element(By.CSS_SELECTOR, f"#page{page_num + 1}")
                driver.execute_script("arguments[0].click();", next_button)
                time.sleep(3)
            except Exception as e:
                print(f"âš ï¸  ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                break

finally:
    driver.quit()
    print(f"\n{'='*60}")
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(data)}ê°œì˜ ë‰´ìŠ¤ ìˆ˜ì§‘")
    print(f"{'='*60}\n")

# ì—‘ì…€ë¡œ ì €ì¥
if data:
    df = pd.DataFrame(data, columns=["ê¸°ê³  ë‚ ì§œ", "ë‰´ìŠ¤ ì œëª©", "ë‰´ìŠ¤ ë‚´ìš©", "3ì¤„ ìš”ì•½"])
    df.to_excel("êµ­ì œë‰´ìŠ¤.xlsx", index=False)
    print("ğŸ“Š 'êµ­ì œë‰´ìŠ¤.xlsx' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"   - ì´ {len(df)}ê°œì˜ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")
else:
    print("âš ï¸  ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")